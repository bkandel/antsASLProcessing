---
title: "Arterial Spin Labeling Processing with ANTsR"
author: "Benjamin M. Kandel"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

Arterial spin labeling (ASL) is a functional MRI technique that can quantitatively measure brain perfusion without using a radioactive tracer.  ASL works by inverting, or ``tagging'', the spin in the blood traveling into the brain.  By subtracting the observed signal when inverting the inflowing blood from the uninverted, natural-state blood, it is possible to obtain an estimate of how much of the MR signal inside the brain is due to inflowing blood. Perfusion changes due to both acute and chronic causes, and quantifying perfusion can lead to insights into neural functioning and biomarkers for tracking diseases.

One of the main issues in ASL signal processing is the very low signal-to-noise ratio (SNR) of the images.  Typically, the SNR is on the order of 1%.  To counteract the low SNR, most ASL acquisitions take many tag-control acquisitions, averaging the observed differences and relying on the Law of Large Numbers to obtain an accurate estimate of the mean tag-control difference.

Because of the low SNR of ASL data, simple averaging of the tag-control difference may be confounded by significant noise and outliers. These outliers may be caused by motion artifacts, random fluctuations in the signal due to low SNR, machine drift, and other undetermined causes.  `R` provides easy access to advanced statistical techniques for dealing with these issues, and as such ASL processing is an ideal test case to highlight what can be achieved by integrating the sophisticated image processing tools from `ANTs`  with the strong statistical libraries available in `R`.


## Overview of Processing
Raw ASL studies consist of a sequence of interleaved "tag" and "control" images.  Calculating brain perfusion from these tag and control images consists of three main steps:

1. Motion correction
2. Noise reduction (optional).  This involves two steps:
 + Minimization of machine drift and physiological noise
 + Rejection of outlier volumes
3. Calculating average difference between tag and control images

ANTsR provides a comprehensive suite of tools for ASL processing and denoising.  To demonstrate the effect of the tools on observed perfusion estimates, we will show the processing in a step-by-step manner.

```{r, echo=FALSE}
#setup
if (!file.exists('data/101_pcasl.nii.gz')){
  download.file('http://files.figshare.com/2049814/pcasl_data.tar.gz', 'data.tar.gz')
  untar('data.tar.gz')
  file.remove('data.tar.gz')
}
```

## Step 1: Motion correction
```{r, fig.show='hold'}
library(ANTsR)
library(ggplot2)
library(RColorBrewer)
library(grid)
library(reshape2)
pcasl <- antsImageRead('data/101_pcasl.nii.gz')
probs.t1 <- imageFileNames2ImageList(list.files('data', 'prob', full.names=T))
moco <- antsMotionCalculation(pcasl)
tsdat <- timeseries2matrix(moco$moco_img, moco$moco_mask)
moco.names <- grep("MOCO", names(moco$moco_params))
mocoparams <- moco$moco_params[, moco.names]
timepoints <- 1:nrow(tsdat)
# Look at translation of head
mocomeans <- matrix( rep(colMeans(mocoparams)[1:3], nrow(mocoparams)),
      nrow=nrow(mocoparams), byrow=T)
trans <- mocoparams[, 1:3] - mocomeans
names(trans) <- c("X", "Y", "Z")
mydf <- cbind(data.frame(timepoints=timepoints), trans)
mydf.m <- melt(mydf, id.vars='timepoints')
names(mydf.m)[2] <- "Direction"
ggplot(mydf.m, aes(timepoints, value)) + geom_line(aes(colour=Direction)) +
  labs(title="Displacement vs. Timepoint", x = "Time", y = "Displacement")
```

Motion in 2D ASL acquisitions is particularly pernicious because of the
necessity of taking tens of sets of tag-control pairs.  Movement invalidates
the assumption of spatial stability necessary for meaningful averaging of
multiple tag-control pairs and must be corrected for.


Once we have the motion-corrected time series, we can plot the average signal
to get a sense of the structure of the data and noise.
```{r}
tpoints <- data.frame(Timepoint=1:nrow(tsdat), Value=rowMeans(tsdat))
ggplot(tpoints, aes(Timepoint, Value)) + geom_line() +
  geom_smooth(method='loess')
```

The jagged line indicates the whole time-series, whereas the smoothed
trendline indicates the amount of machine and physiological drift.  If the
physiological drift is not removed from the calculation of perfusion, the
effect of tagging blood will be conflated with the drift, leading to a decrease
in accuracy of perfusion calculation.

To enable segmentation of the ASL images, we must register the ASL image to the T1 structural image.
```{r}
t1 <- antsImageRead('data/101_t1.nii.gz')
avg.asl <- getAverageOfTimeSeries(pcasl)
reg <- antsRegistration(avg.asl, t1, 'SyNBold')
seg.t1 <- antsImageRead('data/101_seg.nii.gz')
seg.asl <- antsApplyTransforms(avg.asl, seg.t1, reg$fwdtransforms, interpolator='MultiLabel')
probs <- list()
for(ii in 1:length(probs.t1)){
  probs[[ii]] <- antsApplyTransforms(avg.asl, probs.t1[[ii]], reg$fwdtransforms)
}
gm <- thresholdImage(seg.asl, 2, 2) + thresholdImage(seg.asl, 4, 4)
gmdat <- timeseries2matrix(moco$moco_img, gm)
gmpoints <- data.frame(Volume=1:nrow(gmdat), Value=rowMeans(gmdat))
ggplot(gmpoints, aes(Volume, Value)) + geom_line()
```


Although it is clear that as a whole, there is strong signal in the gray matter, the noise in individual voxels can outweigh the signal.  As an example, here are timeseries plots for a few randomly chosen points in the gray matter:
```{r}
nvox <- 4
myvox <- sample(ncol(gmdat), nvox)
df.samp <- data.frame(matrix(rep(NA, nvox*nrow(gmdat)), nrow=nvox))
rownames(df.samp) <- paste('Voxel', 1:nvox)
#colnames(df.samp) <- paste('Volume', 1:nrow(gmdat))
df.samp <- rbind(df.samp, 1:nrow(gmdat))
rownames(df.samp)[nrow(df.samp)] <- 'Volume'
df.samp <- t(df.samp)
df.samp <- NULL
for (ii in 1:length(myvox)){
  df.samp <- rbind(df.samp, data.frame(
    Voxel=as.factor(rep(ii, nrow(gmdat))), Value=gmdat[, myvox[ii]], Volume=1:nrow(gmdat)))
}
ggplot(df.samp, aes(x=Volume, y=Value, colour=Voxel, group=Voxel)) +
  geom_point() + geom_line()
```

Clearly, the noise patterns are not homogeneous throughout the gray matter, and have significant impact on the observed values.


